{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" \n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import Sampler\n",
    "import chess\n",
    "import chess.pgn\n",
    "import math\n",
    "from pathlib import Path\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import optim\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "classes=['AI GAME', 'AI WHITE', 'AI BLACK', 'HUMAN GAME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fen_sequence_to_tensor(fen_list):\n",
    "    '''\n",
    "        Input: String list. A list of fen codes that are in ordered sequence\n",
    "        Output: 4D tensor to input into Neural Net. Dimensions of tensor are (6,20,8,8)\n",
    "    '''\n",
    "    t = torch.zeros(6,20,8,8)\n",
    "    for i in range(6):\n",
    "        for j in range(20):\n",
    "            board = chess.Board(fen=fen_list[j])\n",
    "            for color_bool in [True,False]:\n",
    "                piece_loc_indexes = list(board.pieces(piece_type=i+1,color=color_bool))\n",
    "                for inx in piece_loc_indexes:\n",
    "                    x = math.floor(inx / 8)\n",
    "                    y = inx % 8\n",
    "                    #set the tensor, we flip x axis to make it easier to look at\n",
    "                    t[i][j][7-x][y] = 1\n",
    "    return t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomRows2Cols(t):\n",
    "    r = random.randint(1,100)\n",
    "    if r <= 95:\n",
    "        return t\n",
    "    flipped = torch.flip(t,[2,3])\n",
    "    return flipped\n",
    "\n",
    "def augmentation_6x6(t):\n",
    "    for i in t:\n",
    "        for j in i:\n",
    "            indices = (j == 1).nonzero(as_tuple=False)\n",
    "            for inx in indices:\n",
    "                if 0 in inx or 7 in inx:\n",
    "                    j[inx[0]][inx[1]] = 0\n",
    "    return t\n",
    "\n",
    "def augmentation_6x8(t):\n",
    "    for i in t:\n",
    "        for j in i:\n",
    "            indices = (j == 1).nonzero(as_tuple=False)\n",
    "            for inx in indices:\n",
    "                if 0 in inx[0] or 7 in inx[0]:\n",
    "                    j[inx[0]][inx[1]] = 0\n",
    "    return t\n",
    "\n",
    "def randomCrop(t):\n",
    "    #10% chance to crop the data\n",
    "    r = random.randint(1,100)\n",
    "    if r <= 5:\n",
    "        return augmentation_6x6(t)\n",
    "    elif r <= 10:\n",
    "        return augmentation_6x8(t)\n",
    "    else:\n",
    "        return t "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Lambda(randomCrop), transforms.Lambda(randomRows2Cols)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessSeq(Dataset):\n",
    "\n",
    "    \n",
    "\n",
    "    def __init__(self,path):\n",
    "        # Iterate through training directories and create a list of tuples (filename, label)\n",
    "        divide_num_files_to_read = 1\n",
    "        print(\"0\")\n",
    "        files = Path(path / \"AvA\").glob('*.txt')\n",
    "        items = [(str(f),\"0\") for f in files][::divide_num_files_to_read]\n",
    "        print(\"1\")\n",
    "        files = Path(path / \"A_W\").glob('*.txt')\n",
    "        items = items + [(str(f),\"1\") for f in files][::divide_num_files_to_read]\n",
    "        print(\"2\")\n",
    "        files = Path(path / \"A_B\").glob('*.txt')\n",
    "        items = items + [(str(f),\"2\") for f in files][::divide_num_files_to_read]\n",
    "        print(\"3\")\n",
    "        files = Path(path / \"HvH\").glob('*.txt')\n",
    "        items = items + [(str(f),\"3\") for f in files][::divide_num_files_to_read]\n",
    "        print(\"4\")\n",
    "        self.items = items\n",
    "        self.length = len(self.items)\n",
    "        self.transform = transform\n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        filename, label = self.items[index]\n",
    "        f = open(filename)\n",
    "        fen_array = f.readlines()\n",
    "        seqTensor = fen_sequence_to_tensor(fen_array)\n",
    "        f.close()\n",
    "        seqTensor = self.transform(seqTensor)\n",
    "        return (seqTensor, int(label))    \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 128\n",
    "path = Path.cwd()\n",
    "writer = SummaryWriter(\"runs/final_2\")\n",
    "\n",
    "sample_weights = [1/x for x in [303168,33952,36853,132609]]\n",
    "\n",
    "sampler_train = WeightedRandomSampler(weights=sample_weights, num_samples = 50000,replacement=True)\n",
    "sampler_valid_test = WeightedRandomSampler(weights=sample_weights, num_samples = 50000,replacement=True)\n",
    "\n",
    "train_chessseq = ChessSeq(path / \"train\")\n",
    "valid_chessseq = ChessSeq(path / \"valid\")\n",
    "test_chessseq = ChessSeq(path / \"test\")\n",
    "\n",
    "'''\n",
    "train_loader = torch.utils.data.DataLoader(train_chessseq, batch_size = bs, sampler= sampler_train)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_chessseq, batch_size = bs, sampler=sampler_valid_test)\n",
    "test_loader  = torch.utils.data.DataLoader(test_chessseq, batch_size = bs, sampler=sampler_valid_test)\n",
    "'''\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_chessseq, batch_size = bs, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_chessseq, batch_size = bs, shuffle=True)\n",
    "test_loader  = torch.utils.data.DataLoader(test_chessseq, batch_size = bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_batch, labels_batch = next(iter(train_loader))\n",
    "print(labels_batch)\n",
    "print(data_batch.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTING\n",
    "\n",
    "fen_sequence_to_tensor(['r2q1rk1/pb1nbppp/2p2n2/1p2p1B1/4P3/1BN2N2/PPP1QPPP/R4RK1 w - - 2 11',\n",
    "'r2q1rk1/pb1nbppp/2p2n2/1p2p1B1/4P3/1BN2N2/PPP1QPPP/3R1RK1 b - - 3 11',\n",
    "'r4rk1/pbqnbppp/2p2n2/1p2p1B1/4P3/1BN2N2/PPP1QPPP/3R1RK1 w - - 4 12',\n",
    "'r4rk1/pbqnbppp/2p2n2/1p2p1B1/4P3/1BN2N2/PPPRQPPP/5RK1 b - - 5 12',\n",
    "'r4rk1/1bqnbppp/2p2n2/pp2p1B1/4P3/1BN2N2/PPPRQPPP/5RK1 w - - 0 13',\n",
    "'r4rk1/1bqnbppp/2p2n2/pp2p1B1/4P3/PBN2N2/1PPRQPPP/5RK1 b - - 0 13',\n",
    "'r4rk1/1bqnbppp/2p2n2/p3p1B1/1p2P3/PBN2N2/1PPRQPPP/5RK1 w - - 0 14',\n",
    "'r4rk1/1bqnbppp/2p2n2/p3p1B1/1P2P3/1BN2N2/1PPRQPPP/5RK1 b - - 0 14',\n",
    "'r4rk1/1bqnbppp/2p2n2/4p1B1/1p2P3/1BN2N2/1PPRQPPP/5RK1 w - - 0 15',\n",
    "'r4rk1/1bqnbppp/2p2n2/4p1B1/1p2P3/1B3N2/NPPRQPPP/5RK1 b - - 1 15',\n",
    "'r4rk1/1bqnbppp/5n2/2p1p1B1/1p2P3/1B3N2/NPPRQPPP/5RK1 w - - 0 16',\n",
    "'r4rk1/1bqnbppp/5n2/2p1p1B1/1p2P3/1B3N2/1PPRQPPP/2N2RK1 b - - 1 16',\n",
    "'r4rk1/2qnbppp/b4n2/2p1p1B1/1p2P3/1B3N2/1PPRQPPP/2N2RK1 w - - 2 17',\n",
    "'r4rk1/2qnbppp/b4n2/2p1p1B1/1pB1P3/5N2/1PPRQPPP/2N2RK1 b - - 3 17',\n",
    "'r4rk1/2qnbppp/5n2/2p1p1B1/1pb1P3/5N2/1PPRQPPP/2N2RK1 w - - 0 18',\n",
    "'r4rk1/2qnbppp/5n2/2p1p1B1/1pQ1P3/5N2/1PPR1PPP/2N2RK1 b - - 0 18',\n",
    "'r4rk1/2q1bppp/1n3n2/2p1p1B1/1pQ1P3/5N2/1PPR1PPP/2N2RK1 w - - 1 19',\n",
    "'r4rk1/2q1bppp/1n3n2/2p1p1B1/1p2P3/5N2/1PPRQPPP/2N2RK1 b - - 2 19',\n",
    "'r4rk1/2q1bppp/5n2/2p1p1B1/np2P3/5N2/1PPRQPPP/2N2RK1 w - - 3 20',\n",
    "'r4rk1/2q1bppp/5n2/2p1p1B1/np2P3/1P3N2/2PRQPPP/2N2RK1 b - - 0 20',\n",
    "])[0][0] #kings, first move of sequence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_pr_curve(class_inx, probs, label, global_step=0):\n",
    "    tb_truth = label == class_inx\n",
    "    tb_probs = probs[:, class_inx]\n",
    "    writer.add_pr_curve(classes[class_inx],\n",
    "                        tb_truth,\n",
    "                        tb_probs,\n",
    "                        global_step=global_step)\n",
    "\n",
    "def calculate_precision_recall_f1(probs, label):\n",
    "    \n",
    "    metrics_dict = {}\n",
    "    label = label.cpu().detach().numpy()\n",
    "    probs = probs.cpu().detach().numpy().round()\n",
    "\n",
    "    choices = np.array([np.argmax(item) for item in probs])\n",
    "\n",
    "    tp_count = int((np.array(choices == 0) & np.array(label == 0)).sum())\n",
    "    tn_count = int((np.array(choices == 1) & np.array(label == 1)).sum())\n",
    "    \n",
    "    fp_count = int((np.array(choices == 1) & np.array(label == 0)).sum())\n",
    "    fn_count = int((np.array(choices == 0) & np.array(label == 1)).sum())\n",
    "\n",
    "    print(tp_count, fp_count, fn_count, tn_count)\n",
    "    precision = metrics_dict['pr/precision'] = tp_count / np.float32(tp_count + fp_count)\n",
    "    recall = metrics_dict['pr/recall'] = tp_count / np.float32(tp_count + fn_count)\n",
    "    metrics_dict['pr/f1'] = 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    return metrics_dict\n",
    "\n",
    "def make_confusion_matrix(probs, label):\n",
    "    label = label.cpu().detach().numpy()\n",
    "    probs = probs.cpu().detach().numpy().round()\n",
    "\n",
    "    choices = np.array([np.argmax(item) for item in probs])\n",
    "\n",
    "    cf_matrix = confusion_matrix(label, choices)\n",
    "    df_cm = pd.DataFrame(cf_matrix, index=[i for i in classes],\n",
    "                         columns=[i for i in classes])\n",
    "    plt.figure(figsize=(6, 6))   \n",
    "    hm = sn.heatmap(df_cm, annot=True).get_figure()\n",
    "\n",
    "    hm.savefig('conf_matr.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ChessNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=4, conv_channels=8):\n",
    "        super(ChessNet, self).__init__()\n",
    "        \n",
    "        self.b1 = ChessBlock(6,conv_channels)\n",
    "        self.b2 = ChessBlock(conv_channels,conv_channels * 2)\n",
    "        self.b3 = ChessBlock(conv_channels * 2,conv_channels * 4)\n",
    "        #self.b4 = ChessBlock(conv_channels * 4,conv_channels * 8)\n",
    "        self.batchnorm = nn.BatchNorm3d(6)\n",
    "        self.linear = nn.Sequential( \n",
    "            nn.Linear(2048, 128), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_out = self.batchnorm(x)\n",
    "        b = self.b1(batch_out)\n",
    "        b = self.b2(b)\n",
    "        b = self.b3(b)\n",
    "        #b = self.b4(b)\n",
    "        \n",
    "        b = torch.flatten(b, 1)\n",
    "        b = self.linear(b)\n",
    "        return b\n",
    "\n",
    "class ChessBlock(nn.Module):\n",
    "    def __init__(self, in_channels, conv_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv3d(in_channels, conv_channels, kernel_size=(5,3,3), stride=(2,1,1), padding=(2,1,1), bias=True)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv3d(conv_channels, conv_channels , kernel_size=(5,3,3), stride=(2,1,1), padding=(2,1,1), bias=True)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.pool = nn.MaxPool3d(kernel_size=(5,3,3), stride=(2,1,1), padding=(2,1,1))\n",
    "        \n",
    "\n",
    "    def forward(self, input_batch):\n",
    "        b = self.conv1(input_batch)\n",
    "        b = self.relu1(b)\n",
    "        b = self.conv2(b)\n",
    "        b = self.relu2(b)\n",
    "\n",
    "        return self.pool(b)\n",
    "\n",
    "device=None\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\") \n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "cnn = ChessNet()\n",
    "cnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn, train_loader, val_loader, epochs=15, device=\"cpu\"):\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        training_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        class_probs = [] #for uploading PR metrics\n",
    "        class_label = [] # ^\n",
    "        num_correct=0\n",
    "        num_examples=0\n",
    "\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            \n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            writer.add_graph(model,inputs)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(inputs)\n",
    "\n",
    "            class_probs_batch = [F.softmax(el, dim=0) for el in output]\n",
    "            class_probs.append(class_probs_batch)\n",
    "            class_label.append(targets)\n",
    "\n",
    "            loss = loss_fn(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            training_loss += loss.data.item() * inputs.size(0)\n",
    "\n",
    "            correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets)\n",
    "            num_correct += torch.sum(correct).item()\n",
    "            num_examples += correct.shape[0]\n",
    "\n",
    "        training_loss /= len(train_loader.dataset)\n",
    "        writer.add_scalar(\"Loss/train\", training_loss, epoch)\n",
    "        writer.add_scalar(\"Correct/train\", num_correct/num_examples, epoch)\n",
    "        \n",
    "        model.eval()\n",
    "\n",
    "        num_correct = 0 \n",
    "        num_examples = 0\n",
    "        for batch in val_loader:\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(device)\n",
    "            output = model(inputs)\n",
    "            targets = targets.to(device)\n",
    "            loss = loss_fn(output,targets) \n",
    "            valid_loss += loss.data.item() * inputs.size(0)\n",
    "            correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets)\n",
    "            num_correct += torch.sum(correct).item()\n",
    "            num_examples += correct.shape[0]\n",
    "        valid_loss /= len(val_loader.dataset)\n",
    "        writer.add_scalar(\"Loss/valid\", valid_loss, epoch)\n",
    "        writer.add_scalar(\"Correct/valid\", num_correct, epoch)\n",
    "\n",
    "        print('Epoch: {}, Training Loss: {:.2f}, Validation Loss: {:.2f}, accuracy = {:.2f}'.format(epoch, training_loss,\n",
    "        valid_loss, num_correct / num_examples))\n",
    "        writer.flush()\n",
    "        writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(cnn,optim.Adam(cnn.parameters(),lr=0.0003, weight_decay=1e-5),nn.CrossEntropyLoss(),train_loader,valid_loader,epochs=1,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, device=\"cpu\"):\n",
    "    num_correct=0\n",
    "    total=0\n",
    "    for batch in test_loader:\n",
    "        inputs, targets = batch\n",
    "        inputs = inputs.to(device)\n",
    "        output = model(inputs)\n",
    "        targets = targets.to(device)\n",
    "        correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets)\n",
    "        num_correct += torch.sum(correct).item()\n",
    "        total+=len(correct)\n",
    "    print(\"Prediction accuracy {:.2f}% ({} correct out of {})\".format((num_correct/total)*100,num_correct,total))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_probs = []\n",
    "class_label = []\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        output = cnn(images)\n",
    "        class_probs_batch = [F.softmax(el, dim=0) for el in output]\n",
    "        class_probs.append(class_probs_batch)\n",
    "        class_label.append(labels)\n",
    "\n",
    "test_probs = torch.cat([torch.stack(batch) for batch in class_probs])\n",
    "test_label = torch.cat(class_label)\n",
    "\n",
    "add_pr_curve(0, test_probs, test_label)\n",
    "add_pr_curve(1, test_probs, test_label)\n",
    "make_confusion_matrix(test_probs,test_label)\n",
    "metrics = calculate_precision_recall_f1(test_probs,test_label)\n",
    "print(metrics)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(cnn,test_loader,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_seq = ChessSeq(path / \"experiment_sequences\")\n",
    "exp_loader  = torch.utils.data.DataLoader(experiment_seq, batch_size = 32, shuffle=True)\n",
    "test(cnn, exp_loader,device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e54cde54f3744fea812f5dee20d21f3c57353adb8b4333847e211eec93226ef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
